\section{Methodology} \label{methodology}

This study proposes an investigation on how the scientific research on the \textit{economics of migration} evolved in terms of its topical composition. Following the discussion in section \ref{eco_migration}, we can ask a few questions: has the interest in international migration really continued increasing throughout the 21st century? If so, which topics received the most attention? Besides, how has the research in internal migration evolved after dominating the research agenda during the 20th century? \textit{Our hypothesis is that topics related to internal migration have lost importance, making way for topics related to international migration to increase their participation}. Therefore, we expect to see a greater participation in topics related to international migration in the 21st century, to the detriment of those related to internal migration. 

To break down the composition of topics in the field of \textit{economics of migration}, the method chosen was topic modelling, which is an unsupervised machine learning method of text analysis, through which we can estimate a topic model. Topic models are generative Bayesian probabilistic models that allow us to uncover the semantic structure underlying a collection of documents \citep{blei_latent_2003, blei_topic_2009, evans_machine_2016}. While topic modelling is a relatively recent method, it has proven to be a promising analytical tool for a number of areas in the social sciences. For instance, it has been used to uncover the intellectual structure of documents \citep{griffiths_finding_2004}, assess the content and sentiments in speeches and other types of communication \citep{grimmer_bayesian_2010, hansen_transparency_2018}, and for mapping fields of study \citep{ambrosino_what_2018, pisarevskaya_mapping_2020}. 

Among the many types of topic models, one of the most widely used with discrete text data, and at the same time one of the simplest and most straightforward, is Latent Dirichlet Allocation (LDA)\footnote{For a brief technical presentation about LDA, see Appendix \ref{LDA}.}, which was first proposed by \cite{blei_latent_2003}. Following \cite{pisarevskaya_mapping_2020}, we decided to estimate an LDA topic model, which will be based on abstracts of scientific works. Intuitively speaking, our problem is that we have a corpus of documents (abstracts of scientific works), each consisting of a mixture of topics, but we do not know a priori which topics the documents are about, and that's mainly what we want to find out, so we can proceed to analyse the evolution of the topical composition.

\subsection{LDA topic modelling} \label{topic_modelling}

Prior to actually estimating our LDA topic model, there are a few steps that need to be followed. We start with a corpus of $M$ abstracts of scientific works, each of them made up of a bunch of words. However, LDA extracts the underlying semantic structure of documents, and many of our words do not carry any semantic content; hence, we have to pre-process our text data\footnote{This is a common step in natural language processing (NLP). For a detailed explanation, see \cite[p. 9-12]{ponweiser_latent_2012}.}. Pre-processing involves steps such as (i) tokenization, which is the process of breaking down a text into smaller units called tokens, which can be words or other characters; (ii) the removal of stop words, punctuation, and other unused words; (iii) the adjustment of words with different spellings (British and American, for example), synonyms, and acronyms; (iv) and lemmatization, which is a process that helps standardize words that appear in different grammatical and orthographical forms. 

After pre-processing our text data, we are left with the words that have a semantic content only, which are the ones that form our fixed vocabulary $\{1, \cdots, V \}$. With the fixed vocabulary defined, we shall represent our corpus of $M$ documents as a so-called document-term matrix (DTM)\footnote{Representing our corpus as a DTM is only possible under the bag-of-words assumption \citep{ponweiser_latent_2012}.}, which represents every document in terms of frequencies of words in our fixed vocabulary $V$. An additional step after creating the DTM is to trim less frequent words using a threshold, which is an arbitrary value defined by the authors. Given that LDA topic modelling is quite intensive, computationally speaking, removing less frequent words reduces the size of our fixed vocabulary $V$, which makes computations easier and more efficient. Once we have the DTM, we can finally proceed to estimate the LDA topic model, which is done using Gibbs sampling\footnote{For the sake of brevity, we will omit any technical discussion of Gibbs sampling, but its use when estimating an LDA model is a standard practice. Another common alternative method is variational expectation-maximization (VEM) \citep{grun_topicmodels_2011}.}.

\begin{table}[]
	\centering
	\begin{tabular}{c|cccccc}
           		        & Word 1 ($w_{1}$) & Word 2 ($w_{2}$) & $\cdots$ & Word $n$ ($w_{n}$) & $\cdots$ & Word $V$ ($w_{V}$) \\ \hline
Document 1 ($\mathbf{w}_{1}$) & 1 & 2 & $\cdots$ & 4 & $\cdots$ & 0 \\
Document 2 ($\mathbf{w}_{2}$) & 0 & 4 & $\cdots$ & 3 & $\cdots$ & 0 \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
Document $m$ ($\mathbf{w}_{m}$) & 2 & 2 & $\cdots$ & 0 & $\cdots$ & 1 \\
$\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ & $\vdots$ \\
Document $M$ ($\mathbf{w}_{M}$) & 5 & 0 & $\cdots$ & 1 & $\cdots$ & 2
	\end{tabular}
	\caption{Hypothetical example of a document-term matrix with $M$ documents and $V$ words, adapted from \cite{ponweiser_latent_2012}. The cells indicate how often a word shows up in a document.}
	\label{tab:dtm}
\end{table}

All the computations and estimations were performed using the statistical software R\footnote{Our code to implement LDA topic modelling was built following \href{https://github.com/ccs-amsterdam/r-course-material/blob/master/tutorials/r_text_lda.md}{Wouter van Atteveldt and Kasper Welbers (2020)}. The data repository with all the replication files is available in: .}. Packages \textit{quanteda} and \textit{textstem} were used in the text pre-processing, while the function \textit{LDA} from the package \textit{topicmodels}\footnote{This is an R package that provides basic tools for fitting topic models. For a detailed presentation, see \cite{grun_topicmodels_2011}.} was used to fit our LDA model. There are three elements on the model that need to be defined by us, namely, the hyperparameters $\eta$ and $\alpha$, which are responsible respectively for the sparsity of the distributions of words over topics and topics over documents\footnote{That is, lower values of both $\eta$ and $\alpha$ lead LDA to fit models with sparse distributions. Usually, the benchmark for what is considered low is anything below 1. Therefore, if $\eta, \alpha < 1$, then each topic will be composed by a smaller number of very high-probability words, and each document will be composed by a smaller number of very high-probability topics.}, and the number of latent topics $K$, which was chosen with the help of the \textit{ldatuning} package\footnote{The \textit{ldatuning} package computes four metrics--Griffiths2004 \citep{griffiths_finding_2004}, CaoJuan2009 \citep{cao_density-based_2009}, Arun2010 \citep{arun_finding_2010}, and Deveaud2014 \citep{deveaud_accurate_2014}--whose results are the statistically optimal number of topics, whereby the researcher may use all of them to make their decision, or only those they deem appropriate.}. It's worth pointing out that there are no single values that are the correct ones for any of these three parameters, so their definition is thus a research decision. Since LDA is a probabilistic generative process, the fitted LDA topic model produces as outcomes two matrices of probability distributions, the \textit {matrix of per-topic word probabilities} and the \textit{matrix of per-document topic probabilities}. 

The \textit{matrix of per-topic word probabilities} displays the posterior probabilities of words belonging to topics, which will help us understand the content of the topics on the \textit{economics of migration}, and consequently label them\footnote{Remember that LDA is an unsupervised technique, meaning that it learns from the unlabeled data we provide, but it's unable to assess and interpret topics qualitatively \citep{evans_machine_2016}. For a discussion on this, see \cite{chang_reading_2009}.}. In essence, each topic is a list of all the words in the fixed vocabulary, but some words have a much higher probability of belonging to them. Pisarevskaya and colleagues say that ``the 20-30 most probable words for each topic can be helpful in understanding the content of the topic" \citep[p. 460]{pisarevskaya_mapping_2020}. However, in our case, we realized that the 15 most probable words would already be descriptive enough; moreover, presenting fewer words allows us to focus on the most relevant ones for each topic.

The second outcome is the \textit{matrix of per-document topic probabilities}, which exhibits the posterior probabilities of documents belonging to topics. Each document is associated with all the topics with some probability, but some topics have a much higher likelihood to be the actual topics that the documents deal with. Therefore, these probabilities show the proportion of each topic in a document. In the end, these topic proportions can be used to track the trends in topics over time. By grouping the posterior probabilities by topic and year, and averaging them within each year over all of our abstracts, we computed the yearly mean posterior probabilities for each topic, which are considered to be the topic proportions of documents we can expect to have over the years, allowing us to investigate how each topic has changed over time, which is a strategy that can be used to test for our hypothesis.